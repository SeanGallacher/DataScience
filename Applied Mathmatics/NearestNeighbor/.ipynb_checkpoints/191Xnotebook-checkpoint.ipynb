{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/sean/fh_20210731/full_history'\n",
    "files = os.listdir(path)\n",
    "use_pkl = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ADDING FLOAT, MARKETCAP AND SHARES OUTSTANDING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7173it [00:14, 502.16it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# import required module\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "dfIntraDayAV = pd.read_csv(\"/Users/sean/IntradayChangeAV.csv\")\n",
    "dfPremarketAV = pd.read_csv(\"/Users/sean/PremarketChangeAV.csv\")\n",
    "directoryOverview = '/Users/sean/StockOverview2'\n",
    "def remove_suffix(input_string, suffix):\n",
    "    if suffix and input_string.endswith(suffix):\n",
    "        return input_string[:-len(suffix)]\n",
    "    return input_string\n",
    "Float = {}\n",
    "MarketCap = {}\n",
    "SharesOutstanding = {}\n",
    "for file in tqdm(os.scandir(directoryOverview)):\n",
    "    if (file.is_file() and (file.name != '.DS_Store') and not (\"DailyAV.csv\" in file.name)):\n",
    "        symbol = remove_suffix(file.name, \"Overview.csv\")\n",
    "        #print(symbol)\n",
    "        StockOverview = pd.read_csv(file.path)\n",
    "        \n",
    "        try:\n",
    "            Float[symbol] =  int(StockOverview['0'][44])\n",
    "            SharesOutstanding[symbol] = int(StockOverview['0'][43])\n",
    "            MarketCap[symbol] = int(StockOverview['0'][13])\n",
    "        except Exception: \n",
    "            Float[symbol] =  -1\n",
    "            SharesOutstanding[symbol] = -1\n",
    "            MarketCap[symbol] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##REG SHO LIST \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###use alpha vantage data\n",
    "#path = '/Users/sean/StockDailyAlphaVantage'\n",
    "#files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1685it [00:04, 367.46it/s]\n"
     ]
    }
   ],
   "source": [
    "directory = \"/Users/sean/RegShoListNASDAQ/\"\n",
    "regShoList = {}\n",
    "for file in tqdm(os.scandir(directory)):\n",
    "    if (file.is_file() and file.name[0:8] == \"nasdaqth\"):\n",
    "        date = file.name[8:-4]\n",
    "        date = date[:4] + \"-\" + date[4: 6] + \"-\" + date[6:]\n",
    "        info = pd.read_csv(file.path, sep=\"|\")\n",
    "        if str(info['Symbol'][len(info['Symbol']) -1]).isnumeric():\n",
    "            info['Symbol'].pop(len(info['Symbol']) -1)\n",
    "        regShoList[date] = set(info['Symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10521/10521 [31:42<00:00,  5.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 36s, sys: 2min 6s, total: 30min 43s\n",
      "Wall time: 31min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "df_list = []\n",
    "pkl_name = 'o2c-2010.pkl'\n",
    "if use_pkl:\n",
    "    dfs = pd.read_pickle(pkl_name)\n",
    "    # df_list = None\n",
    "    dfs['pct_gain'] = (dfs['pct_gain'])\n",
    "    for i in range(1,6):\n",
    "        dfs['pct_gain'+str(i)] = (dfs['pct_gain'+str(i)])\n",
    "else:\n",
    "    for file in tqdm(files):\n",
    "        symbol = file[:-11]\n",
    "        #print(symbol)\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(path, file), sep=',')\n",
    "        except Exception:\n",
    "            print(symbol)\n",
    "            continue\n",
    "           \n",
    "        #df['symbol'] = symbol\n",
    "        df.replace(0, np.NaN, inplace=True)\n",
    "        df = df[1:]\n",
    "        #datetime, openP, closeP, high, low, volume  = 'date', '1. open', '4. close',  '2. high', '3. low','6. volume'\n",
    "        datetime, openP, closeP, high, low, volume  = 'datetime', 'open', 'close',  'high', 'low','volume'\n",
    "        symbol = remove_suffix(file, '.csv')\n",
    "#         df['pct_gain'] = (df['Close'] - df.shift(1)['Close']) / df.shift(1)['Close']\n",
    "        df['pct_gain'] = (df[closeP] - df[openP]) / df[openP]\n",
    "        #print(df['symbol'])\n",
    "        shiftDFdayBefore = df.shift(1)\n",
    "        df['premarket_gain'] = (df[openP] - shiftDFdayBefore[closeP]) / shiftDFdayBefore[closeP]\n",
    "        try:\n",
    "            df['SharesFloat'] = Float[symbol]\n",
    "            df['SharesOutstanding'] = SharesOutstanding[symbol]\n",
    "            df['MarketCap'] = int(SharesOutstanding[symbol]) * df[openP]\n",
    "        except KeyError:\n",
    "            df['SharesFloat'] = -1\n",
    "            df['SharesOutstanding'] = -1\n",
    "            df['MarketCap'] = -1\n",
    "        shiftDF = df.shift(-1)\n",
    "        df['day1Date'] = shiftDF[datetime]\n",
    "        df['lastMonthHigh'] = 0\n",
    "        df['monthPerformance'] = 0\n",
    "        df['monthOpen'] = 0\n",
    "        df['monthClose'] = 0\n",
    "        dayBeforeClose = df[closeP]\n",
    "        for i in range(1,6):\n",
    "            s1 = df.shift(-i)\n",
    "#             df['pct_gain'+str(i)] = (s1['Close'] - s1.shift(1)['Close'] ) / s1.shift(1)['Close']\n",
    "            df['pct_gain'+str(i)] = (s1[closeP] - s1[openP]) / s1[openP]\n",
    "            df['day'+str(i)+'high_gain'] = (s1[openP] -  s1[openP])/ s1[openP]\n",
    "            df['day'+str(i)+'Low'] = (s1[low] -  s1[openP])/ s1[openP]\n",
    "            df['day'+str(i)+'Close'] = s1[closeP]\n",
    "            df['day'+str(i)+'Open'] = s1[openP]\n",
    "            df['OverNightGain'+str(i)] = (s1[openP] - dayBeforeClose)/s1[openP] \n",
    "            dayBeforeClose = s1[closeP]\n",
    "        for i in range(1,20):\n",
    "            s = df.shift(i)\n",
    "            df['dayBeforeHigh'+str(i)] = s[high]\n",
    "            if i == 19:\n",
    "                df['monthPerformance'] = (df[openP] - s[openP])/ s[openP]\n",
    "                df['monthOpen'] = s[openP]\n",
    "                df['monthClose'] = s[closeP]\n",
    "        monthHigh = 0\n",
    "        columnsHighs = []\n",
    "        for i in range(1,20):\n",
    "            columnsHighs.append('dayBeforeHigh'+str(i))\n",
    "        df['monthHigh'] = df[columnsHighs].max(axis=1)\n",
    "        df.drop(columns=columnsHighs)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b0463bfe24fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    500\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             new_data = concatenate_block_managers(\n\u001b[0m\u001b[1;32m    503\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0m_is_uniform_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mblk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m_is_uniform_join_units\u001b[0;34m(join_units)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;31m# no blocks that would get missing values (can lead to type upcasts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;31m# unless we're an extension dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_na\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_extension\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;31m# no blocks with indexers (as then the dimensions do not fit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;31m# no blocks that would get missing values (can lead to type upcasts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;31m# unless we're an extension dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_na\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_extension\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;31m# no blocks with indexers (as then the dimensions do not fit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mis_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mchunk_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_len\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_flat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchunk_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \"\"\"\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna\u001b[0;34m(obj, inf_as_na)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCExtensionArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_isna_ndarraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf_as_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf_as_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna_ndarraylike\u001b[0;34m(obj, inf_as_na)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_isna_string_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf_as_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf_as_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mneeds_i8_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;31m# this is the NaT pattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna_string_dtype\u001b[0;34m(values, dtype, inf_as_na)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnaobj_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnaobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfs = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(dfs, \"/Users/sean/StockCategoryLists/MASTERFILEPickleNew.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_pickle(\"/Users/sean/StockCategoryLists/MASTERFILEPickleNew.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     datetime   volume   open     high    low  close symbol  pct_gain  \\\n",
      "1  2015-12-28  97077.0  19.88  19.9485  19.80  19.80    RIV -0.004024   \n",
      "2  2015-12-29  17490.0  19.76  19.8900  19.75  19.86    RIV  0.005061   \n",
      "3  2015-12-30   8458.0  19.88  19.9400  19.83  19.94    RIV  0.003018   \n",
      "4  2015-12-31   4103.0  19.94  19.9400  19.85  19.90    RIV -0.002006   \n",
      "5  2016-01-04   3451.0  19.80  19.8800  19.80  19.88    RIV  0.004040   \n",
      "\n",
      "   premarket_gain  SharesFloat  ...  dayBeforeHigh10  dayBeforeHigh11  \\\n",
      "1             NaN           -1  ...              NaN              NaN   \n",
      "2       -0.002020           -1  ...              NaN              NaN   \n",
      "3        0.001007           -1  ...              NaN              NaN   \n",
      "4        0.000000           -1  ...              NaN              NaN   \n",
      "5       -0.005025           -1  ...              NaN              NaN   \n",
      "\n",
      "  dayBeforeHigh12  dayBeforeHigh13  dayBeforeHigh14  dayBeforeHigh15  \\\n",
      "1             NaN              NaN              NaN              NaN   \n",
      "2             NaN              NaN              NaN              NaN   \n",
      "3             NaN              NaN              NaN              NaN   \n",
      "4             NaN              NaN              NaN              NaN   \n",
      "5             NaN              NaN              NaN              NaN   \n",
      "\n",
      "   dayBeforeHigh16  dayBeforeHigh17  dayBeforeHigh18  dayBeforeHigh19  \n",
      "1              NaN              NaN              NaN              NaN  \n",
      "2              NaN              NaN              NaN              NaN  \n",
      "3              NaN              NaN              NaN              NaN  \n",
      "4              NaN              NaN              NaN              NaN  \n",
      "5              NaN              NaN              NaN              NaN  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dfs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-7be146e08950>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-7be146e08950>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    dfs[.head()]\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# reset to here\n",
    "dfs = dfs.rename(columns={'date': 'datetime', '1. open': 'open', '4. close': \"close\", '2. high': \"high\", '3. low': \"low\",'6. volume': \"volume\"})\n",
    "dfs[.head()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_0\n",
    "dfs_0 = dfs.copy()\n",
    "dfs_Test = dfs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfs_0['datetime'] = pd.to_datetime(dfs_0['datetime'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = pd.Timestamp(2019, 8, 27)\n",
    "dfs_0 = dfs_0[dfs_0['datetime'] > first_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_0 = dfs_0[dfs_0['symbol'] != 'DVOL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs_0 = dfs_0[dfs_0['open'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_0 = dfs_0[dfs_0['volume'] > 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_0.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_pkl:\n",
    "    pd.to_pickle(dfs_0, pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dfs_0 = dfs_0.reset_index(drop=True)\n",
    "dfs_0 = dfs_0.sort_values(['symbol','datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfedu = dfs_Test[dfs_Test['symbol'] == 'MOSY']\n",
    "dfsSorted = dfedu.sort_values(['symbol','datetime'])\n",
    "dfsSorted.tail(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs_0 = dfs_0[dfs_0['pct_gain'] < 300]\n",
    "#dfs_0 = dfs_0[dfs_0['pct_gain'] > .06]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Specify MARKET CAP AND FLOAT \n",
    "param = 'allStocks'\n",
    "\n",
    "\n",
    "if (param == 'SmallCapSmallFloat'):\n",
    "    dfs_0 = dfs_0[dfs_0['MarketCap'] < 1200000000]\n",
    "    dfs_0 = dfs_0[dfs_0['SharesFloat'] > 2000000]\n",
    "    dfs_0 = dfs_0[dfs_0['MarketCap'] > 10000000]\n",
    "    dfs_0 = dfs_0[dfs_0['SharesFloat'] < 12000000]\n",
    "elif (param == 'AllStocks'):\n",
    "    pass\n",
    "elif (param == 'Medium+'):\n",
    "    dfs_0 = dfs_0[dfs_0['SharesFloat'] >= 12000000]\n",
    "    dfs_0 = dfs_0[dfs_0['MarketCap'] >= 150000000]\n",
    "elif (param == 'multiDay'):\n",
    "    dfs_0 = dfs_0[dfs_0['pct_gain'] > .05]\n",
    "    dfs_0 = dfs_0[dfs_0['day1high_gain'] > .40]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_small_list = []\n",
    "for name, group in dfs_0.groupby(['datetime']):\n",
    "    dfs_small_list.append(group.sort_values(by='pct_gain', ascending=False).head(10))\n",
    "dfs_small = pd.concat(dfs_small_list).sort_values(['datetime','pct_gain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_small[['pct_gain','pct_gain1', 'pct_gain2', 'pct_gain3', 'pct_gain4', 'pct_gain5', ]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_small[dfs_small['pct_gain'] < 100].plot(x='datetime', y='day1high_gain', figsize=(24,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_small_pre.pct_gain.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_small_pre.pct_gain1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_small[dfs_small.pct_gain > 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_small_list_pre = []\n",
    "for name, group in dfs_0.groupby(['datetime']):\n",
    "    dfs_small_list_pre.append(group.sort_values(by='premarket_gain', ascending=False).head(10))\n",
    "dfs_small_pre = pd.concat(dfs_small_list_pre).sort_values(['datetime','premarket_gain'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_small_pre[dfs_small_pre['datetime']=='2021-06-09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top20df = pd.concat(top20s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top20df[top20df.datetime == _D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_D = pd.Timestamp(2021, 1, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfList = dfs_small[['day1Date', 'symbol']]\n",
    "#print(dfList)\n",
    "dfListPre= dfs_small_pre[['datetime', 'symbol']]\n",
    "dfListPre.to_csv('/Users/sean/StockCategoryLists/AllPreMarketGainers.csv')\n",
    "dfs_small_pre.to_csv('/Users/sean/StockCategoryLists/AllPreMarketGainersFullData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_small.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import datetime\n",
    "def runPercentages(pct_gainCol, df):\n",
    "    Equity = 1\n",
    "    Trades = 0\n",
    "    TradesPerDay = 10\n",
    "    day = 0\n",
    "    dailyEquityGain = 0\n",
    "    equityCurve = {}\n",
    "    df_dict = df.to_dict('records')\n",
    "    currentday = \"2019-08-27\"\n",
    "    \n",
    "    CurrentHigh = 1\n",
    "    CurrentLow = 1\n",
    "    MaxDrawDown = 0\n",
    "    MonthEquity = {'01' : 1, '02' : 1, '03' : 1, '04' : 1, '05' : 1, '06' : 1,\n",
    "                  '07' : 1, '08' : 1, '09' : 1, '10' : 1, '11' : 1, '12' : 1,}\n",
    "   \n",
    "    MonthEquityGain = 0\n",
    "    yearTrades = [0, 0, 0, 0 ,0 ,0 ,0, 0, 0, 0, 0, 0, 0,0,0,0,0,0]\n",
    "    startingYear = 2008\n",
    "    \n",
    "    LEVERAGE = 3.0\n",
    "    regShoEquity = 1\n",
    "    for row in df_dict:\n",
    "\n",
    "        dayOfMonth = str(currentday)[8:10]\n",
    "        month = str(currentday)[5:7]\n",
    "        year = str(currentday)[0:4]\n",
    "        date = year + \"-\" + month + \"-\" + dayOfMonth \n",
    "        if (int(month) < 12 ):\n",
    "            #print(regShoList[date])\n",
    "            if (row['symbol'] in regShoList[date]):\n",
    "                print(row['symbol'] + \" is on REG SHO\" )\n",
    "                regShoEquity += (0 - percent) * LEVERAGE * regShoEquity/TradesPerDay - 0 * (regShoEquity * (LEVERAGE / TradesPerDay) * .004) \n",
    "            else:\n",
    "                yearTrades[int(year)-startingYear] += 1\n",
    "                #print(row['datetime'])\n",
    "                percent = row[pct_gainCol]\n",
    "\n",
    "                if (row['day1high_gain'] > 1.1):\n",
    "                    percent = 1.1\n",
    "                if (row['OverNightGain1'] > 0):\n",
    "                    dailyEquityGain += (0 - percent) * LEVERAGE * Equity/TradesPerDay - (Equity * (LEVERAGE / TradesPerDay) * .004) \n",
    "                    MonthEquityGain += (0 - percent) * LEVERAGE * MonthEquity[month]/TradesPerDay\n",
    "                    Trades +=1\n",
    "                elif (row['day1high_gain'] > .1):\n",
    "                    percent -=.10\n",
    "                    dailyEquityGain += (0 - percent) * LEVERAGE * Equity/TradesPerDay - (Equity * (LEVERAGE / TradesPerDay) * .004) \n",
    "                    MonthEquityGain += (0 - percent) * LEVERAGE * MonthEquity[month]/TradesPerDay\n",
    "                    Trades +=1\n",
    "\n",
    "\n",
    "        if (row['datetime'] != currentday ):\n",
    "            #print(month)\n",
    "            \n",
    "            #df_of_day = df[df['datetime']] == row['datetime']\n",
    "            day +=1\n",
    "            print(\"Equity: \" + str(Equity) + \"  daily gain: \" + str(dailyEquityGain))\n",
    "            Equity+= dailyEquityGain\n",
    "            MonthEquity[month] += MonthEquityGain\n",
    "            dailyEquityGain = 0\n",
    "            MonthEquityGain = 0\n",
    "            \n",
    "            equityCurve[day] = [day, Equity]\n",
    "            if (Equity > CurrentHigh):\n",
    "                CurrentHigh = Equity\n",
    "                CurrentLow = Equity\n",
    "            if (Equity < CurrentLow):\n",
    "                CurrentLow = Equity\n",
    "                DrawDown = (CurrentHigh - CurrentLow) / CurrentHigh\n",
    "                if (MaxDrawDown < DrawDown):\n",
    "                    MaxDrawDown = DrawDown\n",
    "        currentday = row['datetime']\n",
    "        \n",
    "    print('Final Equity---------')\n",
    "    print(Equity)\n",
    "    print(\"Trades: \" + str(Trades))\n",
    "    print(MaxDrawDown)\n",
    "    print(MonthEquity)\n",
    "    print(yearTrades)\n",
    "    \n",
    "    print('Final REG SHO Equity---------')\n",
    "    print(regShoEquity)\n",
    "    return equityCurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(runPercentages('pct_gain1', dfs_small), orient='index', columns=['day', 'equity'])\n",
    "print(data)\n",
    "data[data.day < 3000].plot(x='day', y='equity', figsize=(24,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import datetime\n",
    "def runPercentagesTest(pct_gainCol, df):\n",
    "    Equity = 1\n",
    "    Trades = 0\n",
    "    TradesPerDay = 10\n",
    "    day = 0\n",
    "    dailyEquityGain = 0\n",
    "    equityCurve = {}\n",
    "    df_dict = df.to_dict('records')\n",
    "    currentday = \"2016-08-27\"\n",
    "    \n",
    "    CurrentHigh = 1\n",
    "    CurrentLow = 1\n",
    "    MaxDrawDown = 0\n",
    "    MonthEquity = {'01' : 1, '02' : 1, '03' : 1, '04' : 1, '05' : 1, '06' : 1,\n",
    "                  '07' : 1, '08' : 1, '09' : 1, '10' : 1, '11' : 1, '12' : 1,}\n",
    "   \n",
    "    MonthEquityGain = 0\n",
    "    yearTrades = [0, 0, 0, 0 ,0 ,0 ,0, 0, 0, 0, 0, 0, 0,0,0,0,0,0]\n",
    "    startingYear = 2008\n",
    "    \n",
    "    LEVERAGE = 1.6\n",
    "    regShoEquity = 1\n",
    "    for row in df_dict:\n",
    "\n",
    "        month = str(currentday)[5:7]\n",
    "        year = str(currentday)[0:4]\n",
    "        if (int(month) < 8 ):\n",
    "            if (symbol in regShoList[row['datetime']]):\n",
    "                print(symbol + \" is on REG SHO\" )\n",
    "                regShoEquity += (0 - percent) * LEVERAGE * Equity/TradesPerDay - 0 * (Equity * (LEVERAGE / TradesPerDay) * .004) \n",
    "            yearTrades[int(year)-startingYear] += 1\n",
    "            #print(row['datetime'])\n",
    "            percent = row[pct_gainCol]\n",
    "        \n",
    "            if (row['day1high_gain'] > 1.1):\n",
    "                percent = 1.1\n",
    "            if (row['OverNightGain'] > 0):\n",
    "                dailyEquityGain += (0 - percent) * LEVERAGE * Equity/TradesPerDay - 0 * (Equity * (LEVERAGE / TradesPerDay) * .004) \n",
    "                MonthEquityGain += (0 - percent) * LEVERAGE * MonthEquity[month]/TradesPerDay\n",
    "                Trades +=1\n",
    "            elif (row['day1high_gain'] > .1):\n",
    "                percent -=.10\n",
    "                dailyEquityGain += (0 - percent) * LEVERAGE * Equity/TradesPerDay - 0* (Equity * (LEVERAGE / TradesPerDay) * .004) \n",
    "                MonthEquityGain += (0 - percent) * LEVERAGE * MonthEquity[month]/TradesPerDay\n",
    "                Trades +=1\n",
    "\n",
    "\n",
    "        if (row['datetime'] != currentday ):\n",
    "            #print(month)\n",
    "            \n",
    "            #df_of_day = df[df['datetime']] == row['datetime']\n",
    "            day +=1\n",
    "            print(\"Equity: \" + str(Equity) + \"  daily gain: \" + str(dailyEquityGain))\n",
    "            Equity+= dailyEquityGain\n",
    "            MonthEquity[month] += MonthEquityGain\n",
    "            dailyEquityGain = 0\n",
    "            MonthEquityGain = 0\n",
    "            \n",
    "            equityCurve[day] = [day, Equity]\n",
    "            if (Equity > CurrentHigh):\n",
    "                CurrentHigh = Equity\n",
    "                CurrentLow = Equity\n",
    "            if (Equity < CurrentLow):\n",
    "                CurrentLow = Equity\n",
    "                DrawDown = (CurrentHigh - CurrentLow) / CurrentHigh\n",
    "                if (MaxDrawDown < DrawDown):\n",
    "                    MaxDrawDown = DrawDown\n",
    "        currentday = row['datetime']\n",
    "        \n",
    "    print('Final Equity---------')\n",
    "    print(Equity)\n",
    "    print(\"Trades: \" + str(Trades))\n",
    "    print(MaxDrawDown)\n",
    "    print(MonthEquity)\n",
    "    print(yearTrades)\n",
    "            \n",
    "    print('Final REG SHO Equity---------')\n",
    "    print(regShoEquity)\n",
    "    return equityCurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(runPercentagesTest('pct_gain1', dfs_small), orient='index', columns=['day', 'equity'])\n",
    "print(data)\n",
    "data[data.day < 3000].plot(x='day', y='equity', figsize=(24,4))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import datetime\n",
    "def runPercentagesMULTIDAY(pct_gainCol, df):\n",
    "    Equity = 1\n",
    "    Trades = 0\n",
    "    TradesPerDay = 10\n",
    "    day = 0\n",
    "    dailyEquityGain = 0\n",
    "    equityCurve = {}\n",
    "    df_dict = df.to_dict('records')\n",
    "    currentday = \"2016-08-27\"\n",
    "    \n",
    "    CurrentHigh = 1\n",
    "    CurrentLow = 1\n",
    "    MaxDrawDown = 0\n",
    "    MonthEquity = {'01' : 1, '02' : 1, '03' : 1, '04' : 1, '05' : 1, '06' : 1,\n",
    "                  '07' : 1, '08' : 1, '09' : 1, '10' : 1, '11' : 1, '12' : 1,}\n",
    "   \n",
    "    MonthEquityGain = 0\n",
    "    \n",
    "    for row in df_dict:\n",
    "        #print(row['datetime'])\n",
    "        month = str(currentday)[5:7]\n",
    "        \n",
    "        percent = row[pct_gainCol]\n",
    "        Trades +=1\n",
    "        elif (row['day2high_gain'] > .5):\n",
    "            percent -= .5\n",
    "            dailyEquityGain += (0 - percent) * 2.0 * Equity/TradesPerDay \n",
    "            MonthEquityGain += (0 - percent) * 2.0 * MonthEquity[month]/TradesPerDay \n",
    "        if (row['datetime'] != currentday ):\n",
    "            #print(month)\n",
    "            #df_of_day = df[df['datetime']] == row['datetime']\n",
    "            day +=1\n",
    "            \n",
    "            Equity+= dailyEquityGain\n",
    "            MonthEquity[month] += MonthEquityGain\n",
    "            dailyEquityGain = 0\n",
    "            MonthEquityGain = 0\n",
    "            \n",
    "            equityCurve[day] = [day, Equity]\n",
    "            if (Equity > CurrentHigh):\n",
    "                CurrentHigh = Equity\n",
    "                CurrentLow = Equity\n",
    "            if (Equity < CurrentLow):\n",
    "                CurrentLow = Equity\n",
    "                DrawDown = (CurrentHigh - CurrentLow) / CurrentHigh\n",
    "                if (MaxDrawDown < DrawDown):\n",
    "                    MaxDrawDown = DrawDown\n",
    "        currentday = row['datetime']\n",
    "        \n",
    "    print('Final Equity---------')\n",
    "    print(Equity)\n",
    "    print(MaxDrawDown)\n",
    "    print(MonthEquity)\n",
    "    return equityCurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(runPercentagesMULTIDAY('pct_gain2', dfs_small), orient='index', columns=['day', 'equity'])\n",
    "print(data)\n",
    "data[data.day < 3000].plot(x='day', y='equity', figsize=(24,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statsAnalysis(df):\n",
    "    df_dict = df.to_dict('records')\n",
    "    smallFloatCount = 0 \n",
    "    microFloatCount = 0\n",
    "    mediumPlusFloatCount = 0\n",
    "    \n",
    "    microCapCount = 0\n",
    "    smallCapCount = 0 \n",
    "    mediumCapCount = 0\n",
    "    \n",
    "    for row in df_dict:\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsAnalysis(df_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small[df_small['datetime'] == pd.timestamp(2021,6,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
